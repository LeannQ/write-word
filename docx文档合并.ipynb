{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并docx文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import win32com.client as wc\n",
    "import docx\n",
    "from docxcompose.composer import Composer\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 收集所有路径\n",
    "def get_path(root):\n",
    "    res = list()\n",
    "    info = os.walk(root)\n",
    "    for tu in info:\n",
    "        direc = tu[0]\n",
    "        for file in tu[2]:\n",
    "            path = os.path.join(direc, file)\n",
    "            res.append(path)\n",
    "    return res\n",
    "\n",
    "\n",
    "# Convert doc to docx\n",
    "def doc2docx(doc_path, docx_path):\n",
    "    word = wc.Dispatch(\"Word.Application\")\n",
    "    doc = word.Documents.Open(doc_path)\n",
    "    doc.SaveAs(docx_path, 12)\n",
    "    doc.Close()\n",
    "    word.Quit()\n",
    "    \n",
    "\n",
    "# 合并docx，返回Document实例\n",
    "# 不能够保持格式\n",
    "def merge_obj(paths):\n",
    "    doc = docx.Document()\n",
    "    for i, p in enumerate(paths):\n",
    "        subdoc = docx.Document(p)\n",
    "        \n",
    "        # 最后一个文档不加page reak\n",
    "        if i < len(paths) - 1:\n",
    "            subdoc.add_page_break()\n",
    "        \n",
    "        for elem in subdoc.element.body:\n",
    "            doc.element.body.append(elem)\n",
    "    return doc\n",
    "\n",
    "\n",
    "# 合并docx，保存至文件\n",
    "def merge_docx(outpath, paths):\n",
    "    doc = merge_obj(paths)\n",
    "    doc.save(outpath)\n",
    "\n",
    "    \n",
    "# 合并docx，保存至文件。版本2\n",
    "def merge_docx_v2(outpath, paths):\n",
    "    print('要合并的文档数量：', len(paths))\n",
    "    master = docx.Document(paths[0])\n",
    "    composer = Composer(master)\n",
    "    for p in tqdm.tqdm(paths[1:]):\n",
    "        try:\n",
    "            doc = docx.Document(p)\n",
    "            # doc.add_page_break()\n",
    "            composer.append(doc)\n",
    "        except:\n",
    "            print(p)\n",
    "    composer.save(outpath)\n",
    "\n",
    "\n",
    "# 合并docx，不断保存。版本3\n",
    "def merge_docx_v3(outpath, paths):\n",
    "    print('要合并的文档数量：', len(paths))\n",
    "    \n",
    "    # 先拷贝一份第一个文档\n",
    "    obj = docx.Document(paths[0])\n",
    "    obj.save(outpath)\n",
    "\n",
    "    for p in tqdm.tqdm(paths[1:]):\n",
    "        master = docx.Document(outpath)\n",
    "        composer = Composer(master)\n",
    "        doc = docx.Document(p)\n",
    "        composer.append(doc)\n",
    "        composer.save(outpath)\n",
    "    \n",
    "\n",
    "# 合并docx，输出信息\n",
    "class Merger:\n",
    "    def __init__(self, datadir, merged_path, info_path):\n",
    "        self.datadir = datadir\n",
    "        self.merged_path = merged_path\n",
    "        self.info_path = info_path\n",
    "        \n",
    "        self.data_paths = get_path(self.datadir)\n",
    "        self.metas = list()\n",
    "        self.docxpaths = list()\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_path_suffix(p):\n",
    "        _, suffix = os.path.splitext(p)\n",
    "        return suffix\n",
    "    \n",
    "    @staticmethod\n",
    "    def must_docx(p):\n",
    "        suffix = Merger.get_path_suffix(p)\n",
    "        if suffix == '.docx':\n",
    "            return p\n",
    "        elif suffix == '.doc':\n",
    "            docxp = p + 'x'\n",
    "            if os.path.exists(docxp):\n",
    "                doc2docx(p, docxp)\n",
    "            return docxp\n",
    "        else:\n",
    "            return None\n",
    "                    \n",
    "    def merge(self):\n",
    "        docxpaths = list()\n",
    "        # 收集docx路径和文件信息\n",
    "        for p in tqdm.tqdm(self.data_paths):\n",
    "            meta = dict()\n",
    "            meta['file_path'] = p\n",
    "            suffix = Merger.get_path_suffix(p)\n",
    "            meta['suffix'] = suffix\n",
    "            p = Merger.must_docx(p)\n",
    "            if p and p not in docxpaths:\n",
    "                docxpaths.append(p)\n",
    "                meta['remark'] = '合并'\n",
    "            else:\n",
    "                meta['remark'] = ''\n",
    "            self.metas.append(meta)\n",
    "        # 合并\n",
    "        self.docxpaths = docxpaths\n",
    "        merge_docx_v2(self.merged_path, docxpaths)\n",
    "        # 保存文件信息\n",
    "        self.write_excel()\n",
    "        \n",
    "    def write_excel(self):\n",
    "        df = pd.DataFrame(self.metas)\n",
    "        df.to_excel(self.info_path, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File numbers:  20\n",
      "{'.xlsx', '.docx'}\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "workdir = r'G:\\ECPH_LY\\Data\\协助同事\\刘艳'\n",
    "# filedir = os.path.join(workdir, 'test')\n",
    "# filedir = os.path.join(workdir, '文档')\n",
    "# filedir = os.path.join(workdir, '202107-202109传统竹家具词条撰写')\n",
    "# filedir = os.path.join(workdir, '家具场景（88条）')\n",
    "filedir = os.path.join(workdir, '儿科护理（一审后清稿）')\n",
    "outpath = os.path.join(workdir, '儿科护理审稿后.docx')\n",
    "info_path = os.path.join(workdir, 'info.xlsx')\n",
    "\n",
    "# 获取所有路径\n",
    "paths = get_path(filedir)\n",
    "print('File numbers: ', len(paths))\n",
    "\n",
    "# 获取所有文件类型\n",
    "suffix = [os.path.splitext(p)[1] for p in paths]\n",
    "print(set(suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 20010.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "要合并的文档数量： 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 9/18 [00:00<00:00, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\ECPH_LY\\Data\\协助同事\\刘艳\\儿科护理（一审后清稿）\\8.16 儿童和青少年常见心理及行为障碍患儿护理.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████████████████████████████████████▎             | 15/18 [00:01<00:00,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\ECPH_LY\\Data\\协助同事\\刘艳\\儿科护理（一审后清稿）\\8.5 营养性疾病患儿护理.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████████▍    | 17/18 [00:02<00:00,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\ECPH_LY\\Data\\协助同事\\刘艳\\儿科护理（一审后清稿）\\8.7 呼吸系统疾病患儿护理.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:02<00:00,  8.34it/s]\n",
      "C:\\Users\\dbk\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 执行合并\n",
    "merger = Merger(filedir, outpath, info_path)\n",
    "merger.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新的任务：按顺序合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用继承\n",
    "class SortMerger(Merger):\n",
    "    def __init__(self, sort_func, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.sort_func = sort_func\n",
    "    \n",
    "    def merge(self):\n",
    "        docxpaths = list()\n",
    "        # 收集docx路径和文件信息\n",
    "        for p in tqdm.tqdm(self.data_paths):\n",
    "            meta = dict()\n",
    "            meta['file_path'] = p\n",
    "            suffix = Merger.get_path_suffix(p)\n",
    "            meta['suffix'] = suffix\n",
    "            p = Merger.must_docx(p)\n",
    "            if p and p not in docxpaths:\n",
    "                docxpaths.append(p)\n",
    "                meta['remark'] = '合并'\n",
    "            else:\n",
    "                meta['remark'] = ''\n",
    "            self.metas.append(meta)\n",
    "        # 合并\n",
    "        docxpaths = self.sort_func(docxpaths)  # 这里发生了变化\n",
    "        self.docxpaths = docxpaths\n",
    "        merge_docx_v2(self.merged_path, docxpaths)\n",
    "        # 保存文件信息\n",
    "        self.write_excel()\n",
    "\n",
    "        \n",
    "def get_head_digit(path):\n",
    "    name = os.path.split(path)[1]\n",
    "    pat = re.compile('^[\\d]{1,5}')\n",
    "    m = re.match(pat, name)\n",
    "    if m:\n",
    "        return int(m.group())\n",
    "    return 1e10\n",
    "\n",
    "def sort_func(lst):    \n",
    "    r = sorted(lst, key=get_head_digit)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File numbers:  201\n",
      "{'.docx'}\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "workdir = r'G:\\ECPH_LY\\Data\\协助同事\\孙冬梅'\n",
    "filedir = os.path.join(workdir, '第四批作家词条回稿文件')\n",
    "outpath = os.path.join(workdir, '第四批作家词条回稿文件.docx')\n",
    "info_path = os.path.join(workdir, 'info.xlsx')\n",
    "\n",
    "# 获取所有路径\n",
    "paths = get_path(filedir)\n",
    "print('File numbers: ', len(paths))\n",
    "\n",
    "# 获取所有文件类型\n",
    "suffix = [os.path.splitext(p)[1] for p in paths]\n",
    "print(set(suffix))\n",
    "\n",
    "# 测试排序\n",
    "# sorted_paths = sort_func(paths)\n",
    "# for p in sorted_paths:\n",
    "#     print(get_head_digit(p))\n",
    "# print(sorted_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 201/201 [00:00<00:00, 67042.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "要合并的文档数量： 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:09<00:00, 22.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# 执行合并\n",
    "merger = SortMerger(sort_func, filedir, outpath, info_path)\n",
    "merger.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新的任务：执行多个合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 85/85 [00:00<00:00, 42619.95it/s]\n",
      " 21%|█████████████████▎                                                               | 18/84 [00:00<00:00, 175.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File numbers:  85\n",
      "{'.docx'}\n",
      "要合并的文档数量： 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 124.40it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 72/72 [00:00<00:00, 72211.83it/s]\n",
      " 17%|█████████████▋                                                                   | 12/71 [00:00<00:00, 113.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File numbers:  72\n",
      "{'.docx'}\n",
      "要合并的文档数量： 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 71/71 [00:00<00:00, 129.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 76/76 [00:00<?, ?it/s]\n",
      " 13%|██████████▉                                                                       | 10/75 [00:00<00:00, 86.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File numbers:  76\n",
      "{'.docx'}\n",
      "要合并的文档数量： 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 98.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:00<?, ?it/s]\n",
      " 21%|█████████████████▎                                                                 | 9/43 [00:00<00:00, 82.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File numbers:  44\n",
      "{'.docx'}\n",
      "要合并的文档数量： 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 43/43 [00:00<00:00, 115.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 23073.19it/s]\n",
      " 59%|███████████████████████████████████████████████▊                                 | 13/22 [00:00<00:00, 108.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File numbers:  23\n",
      "{'.docx'}\n",
      "要合并的文档数量： 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 98.92it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 92/92 [00:00<00:00, 92248.62it/s]\n",
      " 16%|█████████████▎                                                                   | 15/91 [00:00<00:00, 143.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File numbers:  92\n",
      "{'.docx'}\n",
      "要合并的文档数量： 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 91/91 [00:00<00:00, 107.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<?, ?it/s]\n",
      " 37%|██████████████████████████████▌                                                    | 7/19 [00:00<00:00, 52.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File numbers:  20\n",
      "{'.docx'}\n",
      "要合并的文档数量： 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 68.36it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 104/104 [00:00<00:00, 52140.52it/s]\n",
      " 17%|█████████████▏                                                                  | 17/103 [00:00<00:00, 163.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File numbers:  104\n",
      "{'.docx'}\n",
      "要合并的文档数量： 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 103/103 [00:00<00:00, 150.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<?, ?it/s]\n",
      " 27%|█████████████████████▉                                                           | 16/59 [00:00<00:00, 158.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File numbers:  60\n",
      "{'.docx'}\n",
      "要合并的文档数量： 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 59/59 [00:00<00:00, 128.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<?, ?it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 141.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<?, ?it/s]\n",
      "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File numbers:  12\n",
      "{'.docx'}\n",
      "要合并的文档数量： 12\n",
      "File numbers:  31\n",
      "{'.docx'}\n",
      "要合并的文档数量： 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 132.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 64180.62it/s]\n",
      " 10%|████████▏                                                                       | 13/127 [00:00<00:00, 116.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File numbers:  128\n",
      "{'.docx'}\n",
      "要合并的文档数量： 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 107.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 54145.93it/s]\n",
      " 28%|██████████████████████▉                                                          | 15/53 [00:00<00:00, 137.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File numbers:  54\n",
      "{'.docx'}\n",
      "要合并的文档数量： 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 53/53 [00:00<00:00, 110.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "workdir = r'D:\\workdir\\一般性的文档处理\\20220902-合并文档'\n",
    "docx_root = os.path.join(workdir, '安然三审稿')\n",
    "filedirs = [os.path.join(docx_root, d) for d in os.listdir(docx_root)]\n",
    "\n",
    "\n",
    "for d in filedirs:\n",
    "    outpath = os.path.join(docx_root, os.path.basename(d)+'.docx')\n",
    "    info_path = os.path.join(docx_root, os.path.basename(d)+'_info.xlsx')\n",
    "\n",
    "    # 获取所有路径\n",
    "    paths = get_path(d)\n",
    "    print('File numbers: ', len(paths))\n",
    "\n",
    "    # 获取所有文件类型\n",
    "    suffix = [os.path.splitext(p)[1] for p in paths]\n",
    "    print(set(suffix))\n",
    "    \n",
    "    # 执行合并\n",
    "    merger = Merger(d, outpath, info_path)\n",
    "    merger.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下为测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "万云骏.docx\n",
      "何宋苏.docx\n",
      "何静源.docx\n",
      "俞樾.docx\n",
      "俞程競英.docx\n",
      "傅润森.docx\n",
      "刘楚青.docx\n",
      "包丹庭.docx\n",
      "史溥泉.docx\n",
      "叶仰曦.docx\n",
      "叶堂.docx\n",
      "叶小纨.docx\n",
      "叶惠农.docx\n",
      "吴江沈氏家族.docx\n",
      "吴粹伦.doc\n",
      "吴粹伦.docx\n",
      "吴鸿迈.docx\n",
      "周妙中.docx\n",
      "周铨庵.docx\n",
      "唐圭璋.docx\n",
      "唐文治.docx\n",
      "夏煥新.docx\n",
      "孙天申.docx\n",
      "庄一拂.docx\n",
      "张允和.docx\n",
      "张元和.docx\n",
      "张充和.docx\n",
      "张厚衡(4)(1).docx\n",
      "张厚衡.docx\n",
      "张善芗.docx\n",
      "张宗和.docx\n",
      "张琦翔.docx\n",
      "张荫朗 刘珏.docx\n",
      "張麗真.docx\n",
      "徐大椿.docx\n",
      "徐炎之.docx\n",
      "徐燨.docx\n",
      "徐爔.docx\n",
      "徐致靖.docx\n",
      "戴俊.docx\n",
      "戴夏.docx\n",
      "朱再舫.docx\n",
      "朱家溍.docx\n",
      "朱尧亭.docx\n",
      "朱尧文.docx\n",
      "朱復.docx\n",
      "朱经畬.docx\n",
      "朱经畲.docx\n",
      "杨忞.docx\n",
      "林焘.docx\n",
      "柳萱图.docx\n",
      "楼宇烈.docx\n",
      "樊书培.docx\n",
      "樊伯炎.docx\n",
      "樊诵芬.docx\n",
      "樊颖初.docx\n",
      "殷菊侬.docx\n",
      "殷震贤.docx\n",
      "汪健君.docx\n",
      "汪小丹.docx\n",
      "汪鼎丞.docx\n",
      "沈化中.docx\n",
      "沈宠绥.docx\n",
      "沈宪.docx\n",
      "沈永乔.docx\n",
      "沈永令.docx\n",
      "沈珂.docx\n",
      "沈璟.docx\n",
      "沈瓒.docx\n",
      "沈自南.docx\n",
      "沈自友.docx\n",
      "沈自徵.docx\n",
      "沈自昌.docx\n",
      "沈自晋.docx\n",
      "沈自普.docx\n",
      "沈自炳.docx\n",
      "沈自继.docx\n",
      "焦承允.docx\n",
      "爱新觉罗毓婍.docx\n",
      "王西徵.docx\n",
      "王颂椒.docx\n",
      "甘南轩.docx\n",
      "甘律之.docx\n",
      "甘纹轩.docx\n",
      "甘贡三.docx\n",
      "甘长华.docx\n",
      "瞿松涛.docx\n",
      "祝宽.docx\n",
      "穆藕初.docx\n",
      "章元善.docx\n",
      "童斐.docx\n",
      "童曼秋.docx\n",
      "管际安.docx\n",
      "肖漪.docx\n",
      "范崇实.docx\n",
      "蒋复璁.docx\n",
      "蔡安安.docx\n",
      "袁敏宣.docx\n",
      "许宝騋.docx\n",
      "许淑春.docx\n",
      "许潜庵.doc\n",
      "许潜庵.docx\n",
      "许雨香.docx\n",
      "许鸿宾.docx\n",
      "谢锡恩.docx\n",
      "贝祖武.docx\n",
      "赵子敬.docx\n",
      "赵景深.docx\n",
      "邵怀民.docx\n",
      "钱一羽.docx\n",
      "陆剑霞.docx\n",
      "陆坤.docx\n",
      "陆济民.docx\n",
      "陈中凡.docx\n",
      "陈化玲.docx\n",
      "陈受鸟.docx\n",
      "陈古虞.docx\n",
      "陈安娜.docx\n",
      "陈宏亮.docx\n",
      "陈宗枢.docx\n",
      "陈延甫.docx\n",
      "陈靖中.docx\n",
      "陈颖.docx\n",
      "陳安娜.pdf\n",
      "陶光.docx\n",
      "韩耀华.docx\n",
      "项远村.docx\n",
      "项馨吾.docx\n",
      "顾大典.docx\n",
      "魏泽怡.docx\n",
      "一江风曲社.docx\n",
      "上海国际昆曲联谊会.doc\n",
      "上海国际昆曲联谊会.docx\n",
      "上海昆曲研习社.doc\n",
      "上海昆曲研习社.docx\n",
      "上海田笙昆曲研习会.docx\n",
      "东吴大学昆曲社.doc\n",
      "东吴大学昆曲社.docx\n",
      "中原昆曲社.doc\n",
      "中原昆曲社.docx\n",
      "中国政法大学乐和昆曲社.docx\n",
      "中国苏州优兰昆曲社.docx\n",
      "中国音乐学院三生缘曲社.docx\n",
      "兰州昆曲社.docx\n",
      "冬青崑曲社.doc\n",
      "冬青崑曲社.docx\n",
      "北京大学学生京昆社.docx\n",
      "北京师范大学以雅昆曲社.docx\n",
      "北京昆曲研习社.doc\n",
      "北京昆曲研习社.docx\n",
      "北京陶然昆曲学社.docx\n",
      "南京大学昆曲社.docx\n",
      "南京昆曲社.docx\n",
      "南京紫金昆曲社.docx\n",
      "嘉兴玉茗曲社.docx\n",
      "嘉善昆曲研习社.docx\n",
      "四如社.docx\n",
      "复旦大学昆曲研习社.docx\n",
      "天津市昆曲艺术研究会.docx\n",
      "天津昆曲研究会.docx\n",
      "天津甲子曲社.doc\n",
      "天津甲子曲社.docx\n",
      "太仓市娄东昆曲堂名社.docx\n",
      "安徽兰姿京昆研习社.docx\n",
      "宜兴协和会.docx\n",
      "宜兴市昆曲研习社.docx\n",
      "工商学院曲社.docx\n",
      "常州毗陵昆曲社.docx\n",
      "广州昆曲研习社.docx\n",
      "开滦曲会.docx\n",
      "彩云社.docx\n",
      "成都昆曲社.docx\n",
      "扬州市青年昆曲爱好者协会.docx\n",
      "扬州广陵昆曲学社.docx\n",
      "无锡天韵社.docx\n",
      "日本昆剧之友社.docx\n",
      "昆山市缘源曲社.docx\n",
      "昆山昆玉堂昆曲研习社.doc\n",
      "昆山昆玉堂昆曲研习社.docx\n",
      "昆山玉山曲社.docx\n",
      "景璟社.docx\n",
      "杭州大华昆曲社.docx\n",
      "武汉兰韵昆曲社.docx\n",
      "武汉昆曲社.docx\n",
      "江苏省昆剧院兰苑昆曲社.docx\n",
      "河南大学昆曲社.docx\n",
      "河海大学石城昆曲社.docx\n",
      "浙江传媒学院桐音曲社.docx\n",
      "海外崑曲社.docx\n",
      "深圳不止昆曲小组.docx\n",
      "深圳宝安清音昆曲古琴社.docx\n",
      "深圳市和雅昆曲协会.docx\n",
      "深圳昆曲清唱社.docx\n",
      "湖南⽔云昆曲研习社.docx\n",
      "湖南湘女昆曲社.docx\n",
      "溧阳市天目雅韵京昆研习社.docx\n",
      "滋兰昆曲社.docx\n",
      "潇湘昆曲社.docx\n",
      "美西昆曲研究社.docx\n",
      "苏州大学东吴曲社.doc\n",
      "苏州大学东吴曲社.docx\n",
      "苏州天域昆曲社.docx\n",
      "苏州市吴江区清音昆曲社.docx\n",
      "苏州昆剧研习社 道和曲社.docx\n",
      "苏州昆博昆曲社.docx\n",
      "苏州鹤园曲社.docx\n",
      "蓬瀛曲集.docx\n",
      "裘彩萍昆曲研习社.docx\n",
      "辛巳曲社.docx\n",
      "重庆昆曲社.docx\n",
      "长沙昆曲研习社.docx\n",
      "首都师范大学昆玉曲社.docx\n",
      "香港和韻曲社.docx\n",
      "同乐会.docx\n",
      "和桥曲社.docx\n",
      "四川昆词乐班.docx\n",
      "天韵社.docx\n",
      "宜兴协和会.docx\n",
      "怡志楼昆曲研究社.docx\n",
      "成都歗隐社.docx\n",
      "无锡曲局.docx\n",
      "桂阳昆曲南国社.docx\n",
      "深县北街昆弋子弟会.docx\n",
      "耕读会.docx\n",
      "遏云社.docx\n",
      "重庆曲社.docx\n",
      "北京昆曲研习社同期曲会.doc\n",
      "北京昆曲研习社同期曲会.docx\n",
      "安陵曲会.docx\n",
      "扬州竹西同期.docx\n",
      "文津雅集.doc\n",
      "文津雅集.docx\n",
      "曲叙宫商.docx\n",
      "重阳曲会.docx\n",
      "阳羡曲会.docx\n"
     ]
    }
   ],
   "source": [
    "for i in paths:\n",
    "    _, fname = os.path.split(i)\n",
    "    print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
